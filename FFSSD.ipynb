{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1u8VMtqWk82aaJ1x3jn0sECaOnC-Ajo3d",
      "authorship_tag": "ABX9TyPLXBE/9IHHwNPu+7QTs8mW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/Computer-Vision-Papers/blob/main/FFSSD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "Dxxi3XCEgiGN",
        "outputId": "86538f9b-2a90-4bb4-a499-db0ac7b10716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_intermediate_layer_getter\n",
            "  Downloading torch_intermediate_layer_getter-0.1.post1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch_intermediate_layer_getter\n",
            "  Building wheel for torch_intermediate_layer_getter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_intermediate_layer_getter: filename=torch_intermediate_layer_getter-0.1.post1-py3-none-any.whl size=3724 sha256=897c9cdf596b4e2eb2aa2c58defdf3a70b56eafa6894c5c1cb156c0817aba63d\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/11/c0/30d81aa26172d10d68ffaf352b0762eb9fe0a5f5dcf3de63e0\n",
            "Successfully built torch_intermediate_layer_getter\n",
            "Installing collected packages: torch_intermediate_layer_getter\n",
            "Successfully installed torch_intermediate_layer_getter-0.1.post1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install torch_intermediate_layer_getter\n",
        "from torch_intermediate_layer_getter import IntermediateLayerGetter\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#tf"
      ],
      "metadata": {
        "id": "mF7fWlA2Auiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg16 = tf.keras.applications.vgg16.VGG16(weights='imagenet')"
      ],
      "metadata": {
        "id": "BpQ61aN_s7L9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg16.summary()"
      ],
      "metadata": {
        "id": "42cX335Os8KP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(len(vgg16.layers)):\n",
        "#   vgg16.layers[i].trainable=False\n",
        "#   print(vgg16.layers[i].name)"
      ],
      "metadata": {
        "id": "H8HFCKQJkigU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ftb(current_layer, former_layer=None):\n",
        "  x = tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, activation='relu', padding='same')(current_layer)\n",
        "  x = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same')(x)\n",
        "\n",
        "  if former_layer is None:\n",
        "    return x\n",
        "  \n",
        "  elif x.shape == former_layer.shape:\n",
        "    return tf.keras.layers.Add()([x, former_layer])\n",
        "\n",
        "  else:\n",
        "    d = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=4, strides=2, padding='same')(former_layer)\n",
        "    return tf.keras.layers.Add()([x, d])"
      ],
      "metadata": {
        "id": "FzeSzuayTWLJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rfem(x):\n",
        "  channel = x.shape[-1]\n",
        "  #branch1\n",
        "  \n",
        "  x1 = tf.keras.layers.MaxPool2D(pool_size=2, padding='same', strides=1)(x)\n",
        "  x1 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(1, 1), padding='same', activation='relu')(x1)\n",
        "  x1 = tf.keras.layers.BatchNormalization()(x1)\n",
        "\n",
        "  #branch2\n",
        "  x2 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(1, 1), padding='same', activation='relu')(x)\n",
        "  x2 = tf.keras.layers.BatchNormalization()(x2)\n",
        "  x2 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(1, 3), padding='same', activation='relu')(x2)\n",
        "  x2 = tf.keras.layers.BatchNormalization()(x2)\n",
        "\n",
        "  #branch3\n",
        "  x3 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(1, 1), padding='same', activation='relu')(x)\n",
        "  x3 = tf.keras.layers.BatchNormalization()(x3)\n",
        "  x3 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(3, 1), padding='same', activation='relu')(x3)\n",
        "  x3 = tf.keras.layers.BatchNormalization()(x3)\n",
        "\n",
        "  #branch4\n",
        "  x4 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(1, 1), padding='same', activation='relu')(x)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "  x4 = tf.keras.layers.Conv2D(filters=channel//3, kernel_size=(3, 1), padding='same', activation='relu')(x4)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "  x4 = tf.keras.layers.Conv2D(filters=channel//3, kernel_size=(1, 3), padding='same', activation='relu')(x4)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "  x4 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(3, 1), padding='same', activation='relu')(x4)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "  x4 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(1, 3), padding='same', activation='relu')(x4)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "\n",
        "  combined_x = tf.keras.layers.Concatenate(axis=-1)([x1, x2, x3, x4])\n",
        "\n",
        "  return tf.keras.layers.Add()([combined_x, x/0.5])"
      ],
      "metadata": {
        "id": "A4KuDR24YwXz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_x = tf.keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "# x_1  = vgg16.get_layer('input_1')(input_x)\n",
        "\n",
        "# x_2  = vgg16.get_layer('block1_conv1')(x_1)\n",
        "# x_3  = vgg16.get_layer('block1_conv2')(x_2)\n",
        "# x_4  = vgg16.get_layer('block1_pool')(x_3)\n",
        "\n",
        "\n",
        "# x_5  = vgg16.get_layer('block2_conv1')(x_4)\n",
        "# x_6  = vgg16.get_layer('block2_conv2')(x_5)\n",
        "# x_7  = vgg16.get_layer('block2_pool')(x_6)\n",
        "\n",
        "\n",
        "# x_8  = vgg16.get_layer('block3_conv1')(x_7)\n",
        "# x_9  = vgg16.get_layer('block3_conv2')(x_8)\n",
        "# x_10 = vgg16.get_layer('block3_conv3')(x_9)\n",
        "# x_11 = vgg16.get_layer('block3_pool')(x_10)\n",
        "\n",
        "\n",
        "# x_12 = vgg16.get_layer('block4_conv1')(x_11)\n",
        "# x_13 = vgg16.get_layer('block4_conv2')(x_12)\n",
        "# x_14 = vgg16.get_layer('block4_conv3')(x_13)\n",
        "# x_15 = vgg16.get_layer('block4_pool')(x_14)\n",
        "\n",
        "# X1   = vgg16.get_layer('block4_conv3')(rfem(x_13))\n",
        "\n",
        "# x_16 = vgg16.get_layer('block5_conv1')(x_15)\n",
        "# x_17 = vgg16.get_layer('block5_conv2')(x_16)\n",
        "# x_18 = vgg16.get_layer('block5_conv3')(x_17)\n",
        "# x_19 = vgg16.get_layer('block5_pool')(x_18)\n",
        "\n",
        "# X2   = vgg16.get_layer('block5_conv3')(rfem(X1))\n",
        "\n",
        "# x_20 = tf.keras.layers.Conv2D(filters=1024, kernel_size=3, padding='same', activation='relu', name='block6_conv1')(x_19)\n",
        "# x_21 = tf.keras.layers.MaxPool2D(pool_size=2, name='block6_pool')(x_20)\n",
        "\n",
        "# X3   = tf.keras.layers.Conv2D(filters=1024, kernel_size=3, padding='same', activation='relu', name='block6_conv1')(rfem(X2))\n",
        "\n",
        "\n",
        "# x_22 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=2, padding='same', activation='relu', name='block7_conv1')(x_21)\n",
        "# x_23 = tf.keras.layers.MaxPool2D(pool_size=2, name='block7_pool')(x_22)\n",
        "\n",
        "# X4   = tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=2, padding='same', activation='relu', name='block7_conv1')(rfem(X3))\n",
        "\n",
        "# x_24 = tf.keras.layers.Flatten()(x_23)\n",
        "# x_25 = tf.keras.layers.Dense(units=4096, activation='relu', name='dense_layer')(x_24)\n",
        "# x_26 = tf.keras.layers.Dense(units=7, activation='softmax', name='final_layer')(x_25)\n",
        "\n",
        "\n",
        "# X41  = ftb(X4)\n",
        "# X42  = rfem(X41)\n",
        "\n",
        "# X31  = ftb(X3, X41)\n",
        "# X32  = rfem(X31)\n",
        "\n",
        "# X21  = ftb(X2, X31)\n",
        "# X22  = rfem(X21)\n",
        "\n",
        "# X11  = ftb(X1, X21)\n",
        "# X12  = rfem(X11)\n",
        "\n",
        "\n",
        "# # PDM\n",
        "# X4 + X42\n",
        "# X3 + X32\n",
        "# X2 + X22\n",
        "# X1 + X12"
      ],
      "metadata": {
        "id": "o0bQqakqlt_q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = tf.keras.models.Model(inputs=input_x, outputs=[X])"
      ],
      "metadata": {
        "id": "6I5wn93QZZmx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg16_short = tf.keras.models.Model(vgg16.input, vgg16.layers[-5].output)\n",
        "\n",
        "# model_1 = tf.keras.Sequential([\n",
        "#     vgg16_short, \n",
        "#     tf.keras.layers.Conv2D(filters=1024, kernel_size=(3, 3), padding='same', activation='relu', name='block6_conv1'),\n",
        "#     tf.keras.layers.MaxPool2D(pool_size=2, name='block6_pool'),\n",
        "#     tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), strides=2, padding='same', activation='relu', name='block7_conv1'),\n",
        "#     tf.keras.layers.MaxPool2D(pool_size=2, name='block7_pool'),\n",
        "#     tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dense(units=4096, activation='relu', name='dense_layer'),\n",
        "#     tf.keras.layers.Dense(units=7, activation='softmax', name='final_layer')\n",
        "# ])\n",
        "# model_1.summary()"
      ],
      "metadata": {
        "id": "U-5Tqc4-W1cz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_2 = tf.keras.models.Model(inputs=vgg16.input, outputs=[vgg16_short.get_layer('block4_conv2').output,\n",
        "#                                                             vgg16_short.get_layer('block4_conv3').output,\n",
        "#                                                             vgg16_short.get_layer('block5_conv3').output,\n",
        "#                                                             model_1.get_layer('block6_conv1').output,\n",
        "#                                                             model_1.get_layer('block7_conv1').output])"
      ],
      "metadata": {
        "id": "6tc1BmlYWc2k"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pytorch"
      ],
      "metadata": {
        "id": "VNqaRfigAq5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    model = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n",
        "    model.features = torch.nn.Sequential(*([model.features[i] for i in range(30)] + [model.features[i] for i in range(23, 30)]))\n",
        "    return_layers = {'22': 'out_conv4_3', '29': 'out_conv5_3','34': 'out_conv7_2', '36': 'out_conv6_2'}\n",
        "    self.backbone = IntermediateLayerGetter(model.features, return_layers=return_layers)\n",
        "    device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "  def forward(self, images):\n",
        "    return self.backbone(images)"
      ],
      "metadata": {
        "id": "tTweBAlVbjjS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(5,3,512,512)\n",
        "# y = model_with_multuple_layer(x)    \n",
        "\n",
        "encoder = Encoder()\n",
        "y = encoder(x)"
      ],
      "metadata": {
        "id": "gz1caoDAzppq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5286d403-7736-4d65-e35e-8dc33c084d30"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:02<00:00, 238MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[0].keys(), y[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un-boiGn2rvo",
        "outputId": "7f547d1e-6281-4463-b093-7793f56328e6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(odict_keys(['out_conv4_3', 'out_conv7_2', 'out_conv5_3', 'out_conv6_2']),\n",
              " torch.Size([5, 512, 16, 16]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv4_3 = y[0]['out_conv4_3']\n",
        "conv5_3 = y[0]['out_conv5_3'][0]\n",
        "conv6_2 = y[0]['out_conv6_2'][0]\n",
        "conv7_2 = y[0]['out_conv7_2'][0]\n",
        "\n",
        "print(conv4_3.shape, conv5_3.shape, conv6_2.shape, conv7_2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fvp7anur_4Vc",
        "outputId": "7306a21c-c356-414d-fa8e-85105f6ec30d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 512, 64, 64]) torch.Size([5, 512, 32, 32]) torch.Size([5, 512, 32, 32]) torch.Size([5, 512, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ftb(current_layer, former_layer=None):\n",
        "  x = torch.nn.Conv2d(current_layer.shape[1], 256, kernel_size=3, stride=1, padding=1)(current_layer)\n",
        "  x = torch.nn.ReLU(inplace=True)(x)\n",
        "  x = torch.nn.Conv2d(256, 256, kernel_size=3, padding=1)(x)\n",
        "  \n",
        "  if former_layer is None:\n",
        "    return x\n",
        "  elif x.shape == former_layer.shape:\n",
        "    return torch.add(x, former_layer)\n",
        "\n",
        "  else:\n",
        "    d = torch.nn.ConvTranspose2d(former_layer.shape[1], 256, kernel_size=4, stride=2, padding=1)(former_layer)\n",
        "    return torch.add(x, d)"
      ],
      "metadata": {
        "id": "Ef4PrW4Rh1YO"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rfem(x):\n",
        "  channel = x.shape[1]\n",
        "  #branch1\n",
        "  \n",
        "  # x1 = torch.nn.MaxPool2d(kernel_size=2, stride=1, padding=1)(x)\n",
        "  x1 = torch.nn.Conv2d(in_channels=channel, out_channels=channel//4, kernel_size=(1, 1), padding='same')(x)\n",
        "  x1 = torch.nn.ReLU()(x1)\n",
        "  x1 = torch.nn.BatchNorm2d(num_features=channel//4)(x1)\n",
        "\n",
        "  #branch2\n",
        "  x2 = torch.nn.Conv2d(in_channels=channel, out_channels=channel//4, kernel_size=(1, 1), padding='same')(x)\n",
        "  x2 = torch.nn.ReLU()(x2)\n",
        "  x2 = torch.nn.BatchNorm2d(num_features=channel//4)(x2)\n",
        "  x2 = torch.nn.Conv2d(in_channels=channel//4, out_channels=channel//4, kernel_size=(1, 3), padding='same')(x2)\n",
        "  x2 = torch.nn.ReLU()(x2)\n",
        "  x2 = torch.nn.BatchNorm2d(num_features=channel//4)(x2)\n",
        "\n",
        "  #branch3\n",
        "  x3 = torch.nn.Conv2d(in_channels=channel, out_channels=channel//4, kernel_size=(1, 1), padding='same')(x)\n",
        "  x2 = torch.nn.ReLU()(x2)\n",
        "  x3 = torch.nn.BatchNorm2d(num_features=channel//4)(x3)\n",
        "  x3 = torch.nn.Conv2d(in_channels=channel//4, out_channels=channel//4, kernel_size=(3, 1), padding='same')(x3)\n",
        "  x3 = torch.nn.ReLU()(x3)\n",
        "  x3 = torch.nn.BatchNorm2d(num_features=channel//4)(x3)\n",
        "\n",
        "  #branch4\n",
        "  x4 = torch.nn.Conv2d(in_channels=channel, out_channels=channel//4, kernel_size=(1, 1), padding='same')(x)\n",
        "  x4 = torch.nn.ReLU()(x4)\n",
        "  x4 = torch.nn.BatchNorm2d(num_features=channel//4)(x4)\n",
        "  x4 = torch.nn.Conv2d(in_channels=channel//4, out_channels=channel//3, kernel_size=(3, 1), padding='same')(x4)\n",
        "  x4 = torch.nn.ReLU()(x4)\n",
        "  x4 = torch.nn.BatchNorm2d(num_features=channel//3)(x4)\n",
        "  x4 = torch.nn.Conv2d(in_channels=channel//3, out_channels=channel//3, kernel_size=(1, 3), padding='same')(x4)\n",
        "  x4 = torch.nn.ReLU()(x4)\n",
        "  x4 = torch.nn.BatchNorm2d(num_features=channel//3)(x4)\n",
        "  x4 = torch.nn.Conv2d(in_channels=channel//3, out_channels=channel//4, kernel_size=(3, 1), padding='same')(x4)\n",
        "  x4 = torch.nn.ReLU()(x4)\n",
        "  x4 = torch.nn.BatchNorm2d(num_features=channel//4)(x4)\n",
        "  x4 = torch.nn.Conv2d(in_channels=channel//4, out_channels=channel//4, kernel_size=(1, 3), padding='same')(x4)\n",
        "  x4 = torch.nn.ReLU()(x4)\n",
        "  x4 = torch.nn.BatchNorm2d(num_features=channel//4)(x4)\n",
        "\n",
        "  combined_x = torch.concat((x1, x2, x3, x4), dim=1)\n",
        "\n",
        "  return torch.add(combined_x, x/0.5)"
      ],
      "metadata": {
        "id": "9bI20xu2tznb"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# s=ftb(conv4_3, conv5_3)\n",
        "rfem(conv5_3)\n"
      ],
      "metadata": {
        "id": "ottYC5vczvb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "185e9269-c8d0-430a-af79-de9f35d65ef1"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 512, 32, 32])\n",
            "torch.Size([5, 128, 31, 31])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-597df3e00ca9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# s=ftb(conv4_3, conv5_3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrfem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv5_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-553d66a1d918>\u001b[0m in \u001b[0;36mrfem\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m#branch2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 128, 1, 1], expected input[5, 512, 32, 32] to have 128 channels, but got 512 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "My9tQLKLbG4U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}