{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1u8VMtqWk82aaJ1x3jn0sECaOnC-Ajo3d",
      "authorship_tag": "ABX9TyPewzBhMbAvIoJBBW5y+/dr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/Computer-Vision-Papers/blob/main/FFSSD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "Dxxi3XCEgiGN",
        "outputId": "86538f9b-2a90-4bb4-a499-db0ac7b10716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_intermediate_layer_getter\n",
            "  Downloading torch_intermediate_layer_getter-0.1.post1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch_intermediate_layer_getter\n",
            "  Building wheel for torch_intermediate_layer_getter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_intermediate_layer_getter: filename=torch_intermediate_layer_getter-0.1.post1-py3-none-any.whl size=3724 sha256=897c9cdf596b4e2eb2aa2c58defdf3a70b56eafa6894c5c1cb156c0817aba63d\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/11/c0/30d81aa26172d10d68ffaf352b0762eb9fe0a5f5dcf3de63e0\n",
            "Successfully built torch_intermediate_layer_getter\n",
            "Installing collected packages: torch_intermediate_layer_getter\n",
            "Successfully installed torch_intermediate_layer_getter-0.1.post1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install torch_intermediate_layer_getter\n",
        "from torch_intermediate_layer_getter import IntermediateLayerGetter\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#tf"
      ],
      "metadata": {
        "id": "mF7fWlA2Auiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg16 = tf.keras.applications.vgg16.VGG16(weights='imagenet')"
      ],
      "metadata": {
        "id": "BpQ61aN_s7L9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg16.summary()"
      ],
      "metadata": {
        "id": "42cX335Os8KP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(len(vgg16.layers)):\n",
        "#   vgg16.layers[i].trainable=False\n",
        "#   print(vgg16.layers[i].name)"
      ],
      "metadata": {
        "id": "H8HFCKQJkigU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ftb(current_layer, former_layer=None):\n",
        "  x = tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, activation='relu', padding='same')(current_layer)\n",
        "  x = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same')(x)\n",
        "\n",
        "  if former_layer is None:\n",
        "    return x\n",
        "  \n",
        "  elif x.shape == former_layer.shape:\n",
        "    return tf.keras.layers.Add()([x, former_layer])\n",
        "\n",
        "  else:\n",
        "    d = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=4, strides=2, padding='same')(former_layer)\n",
        "    return tf.keras.layers.Add()([x, d])"
      ],
      "metadata": {
        "id": "FzeSzuayTWLJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rfem(x):\n",
        "  channel = x.shape[-1]\n",
        "  #branch1\n",
        "  \n",
        "  x1 = tf.keras.layers.MaxPool2D(pool_size=2, padding='same', strides=1)(x)\n",
        "  x1 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(1, 1), padding='same', activation='relu')(x1)\n",
        "  x1 = tf.keras.layers.BatchNormalization()(x1)\n",
        "\n",
        "  #branch2\n",
        "  x2 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(1, 1), padding='same', activation='relu')(x)\n",
        "  x2 = tf.keras.layers.BatchNormalization()(x2)\n",
        "  x2 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(1, 3), padding='same', activation='relu')(x2)\n",
        "  x2 = tf.keras.layers.BatchNormalization()(x2)\n",
        "\n",
        "  #branch3\n",
        "  x3 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(1, 1), padding='same', activation='relu')(x)\n",
        "  x3 = tf.keras.layers.BatchNormalization()(x3)\n",
        "  x3 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(3, 1), padding='same', activation='relu')(x3)\n",
        "  x3 = tf.keras.layers.BatchNormalization()(x3)\n",
        "\n",
        "  #branch4\n",
        "  x4 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(1, 1), padding='same', activation='relu')(x)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "  x4 = tf.keras.layers.Conv2D(filters=channel//3, kernel_size=(3, 1), padding='same', activation='relu')(x4)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "  x4 = tf.keras.layers.Conv2D(filters=channel//3, kernel_size=(1, 3), padding='same', activation='relu')(x4)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "  x4 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(3, 1), padding='same', activation='relu')(x4)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "  x4 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(1, 3), padding='same', activation='relu')(x4)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "\n",
        "  combined_x = tf.keras.layers.Concatenate(axis=-1)([x1, x2, x3, x4])\n",
        "\n",
        "  return tf.keras.layers.Add()([combined_x, x/0.5])"
      ],
      "metadata": {
        "id": "A4KuDR24YwXz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_x = tf.keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "# x_1  = vgg16.get_layer('input_1')(input_x)\n",
        "\n",
        "# x_2  = vgg16.get_layer('block1_conv1')(x_1)\n",
        "# x_3  = vgg16.get_layer('block1_conv2')(x_2)\n",
        "# x_4  = vgg16.get_layer('block1_pool')(x_3)\n",
        "\n",
        "\n",
        "# x_5  = vgg16.get_layer('block2_conv1')(x_4)\n",
        "# x_6  = vgg16.get_layer('block2_conv2')(x_5)\n",
        "# x_7  = vgg16.get_layer('block2_pool')(x_6)\n",
        "\n",
        "\n",
        "# x_8  = vgg16.get_layer('block3_conv1')(x_7)\n",
        "# x_9  = vgg16.get_layer('block3_conv2')(x_8)\n",
        "# x_10 = vgg16.get_layer('block3_conv3')(x_9)\n",
        "# x_11 = vgg16.get_layer('block3_pool')(x_10)\n",
        "\n",
        "\n",
        "# x_12 = vgg16.get_layer('block4_conv1')(x_11)\n",
        "# x_13 = vgg16.get_layer('block4_conv2')(x_12)\n",
        "# x_14 = vgg16.get_layer('block4_conv3')(x_13)\n",
        "# x_15 = vgg16.get_layer('block4_pool')(x_14)\n",
        "\n",
        "# X1   = vgg16.get_layer('block4_conv3')(rfem(x_13))\n",
        "\n",
        "# x_16 = vgg16.get_layer('block5_conv1')(x_15)\n",
        "# x_17 = vgg16.get_layer('block5_conv2')(x_16)\n",
        "# x_18 = vgg16.get_layer('block5_conv3')(x_17)\n",
        "# x_19 = vgg16.get_layer('block5_pool')(x_18)\n",
        "\n",
        "# X2   = vgg16.get_layer('block5_conv3')(rfem(X1))\n",
        "\n",
        "# x_20 = tf.keras.layers.Conv2D(filters=1024, kernel_size=3, padding='same', activation='relu', name='block6_conv1')(x_19)\n",
        "# x_21 = tf.keras.layers.MaxPool2D(pool_size=2, name='block6_pool')(x_20)\n",
        "\n",
        "# X3   = tf.keras.layers.Conv2D(filters=1024, kernel_size=3, padding='same', activation='relu', name='block6_conv1')(rfem(X2))\n",
        "\n",
        "\n",
        "# x_22 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=2, padding='same', activation='relu', name='block7_conv1')(x_21)\n",
        "# x_23 = tf.keras.layers.MaxPool2D(pool_size=2, name='block7_pool')(x_22)\n",
        "\n",
        "# X4   = tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=2, padding='same', activation='relu', name='block7_conv1')(rfem(X3))\n",
        "\n",
        "# x_24 = tf.keras.layers.Flatten()(x_23)\n",
        "# x_25 = tf.keras.layers.Dense(units=4096, activation='relu', name='dense_layer')(x_24)\n",
        "# x_26 = tf.keras.layers.Dense(units=7, activation='softmax', name='final_layer')(x_25)\n",
        "\n",
        "\n",
        "# X41  = ftb(X4)\n",
        "# X42  = rfem(X41)\n",
        "\n",
        "# X31  = ftb(X3, X41)\n",
        "# X32  = rfem(X31)\n",
        "\n",
        "# X21  = ftb(X2, X31)\n",
        "# X22  = rfem(X21)\n",
        "\n",
        "# X11  = ftb(X1, X21)\n",
        "# X12  = rfem(X11)\n",
        "\n",
        "\n",
        "# # PDM\n",
        "# X4 + X42\n",
        "# X3 + X32\n",
        "# X2 + X22\n",
        "# X1 + X12"
      ],
      "metadata": {
        "id": "o0bQqakqlt_q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = tf.keras.models.Model(inputs=input_x, outputs=[X])"
      ],
      "metadata": {
        "id": "6I5wn93QZZmx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg16_short = tf.keras.models.Model(vgg16.input, vgg16.layers[-5].output)\n",
        "\n",
        "# model_1 = tf.keras.Sequential([\n",
        "#     vgg16_short, \n",
        "#     tf.keras.layers.Conv2D(filters=1024, kernel_size=(3, 3), padding='same', activation='relu', name='block6_conv1'),\n",
        "#     tf.keras.layers.MaxPool2D(pool_size=2, name='block6_pool'),\n",
        "#     tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), strides=2, padding='same', activation='relu', name='block7_conv1'),\n",
        "#     tf.keras.layers.MaxPool2D(pool_size=2, name='block7_pool'),\n",
        "#     tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dense(units=4096, activation='relu', name='dense_layer'),\n",
        "#     tf.keras.layers.Dense(units=7, activation='softmax', name='final_layer')\n",
        "# ])\n",
        "# model_1.summary()"
      ],
      "metadata": {
        "id": "U-5Tqc4-W1cz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_2 = tf.keras.models.Model(inputs=vgg16.input, outputs=[vgg16_short.get_layer('block4_conv2').output,\n",
        "#                                                             vgg16_short.get_layer('block4_conv3').output,\n",
        "#                                                             vgg16_short.get_layer('block5_conv3').output,\n",
        "#                                                             model_1.get_layer('block6_conv1').output,\n",
        "#                                                             model_1.get_layer('block7_conv1').output])"
      ],
      "metadata": {
        "id": "6tc1BmlYWc2k"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pytorch"
      ],
      "metadata": {
        "id": "VNqaRfigAq5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    model = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n",
        "    model.features = torch.nn.Sequential(*([model.features[i] for i in range(30)] + [model.features[i] for i in range(23, 30)]))\n",
        "    return_layers = {'22': 'out_conv4_3', '29': 'out_conv5_3','34': 'out_conv7_2', '36': 'out_conv6_2'}\n",
        "    self.backbone = IntermediateLayerGetter(model.features, return_layers=return_layers)\n",
        "    device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "  def forward(self, images):\n",
        "    return self.backbone(images)"
      ],
      "metadata": {
        "id": "tTweBAlVbjjS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(5,3,512,512)\n",
        "# y = model_with_multuple_layer(x)    \n",
        "\n",
        "encoder = Encoder()\n",
        "y = encoder(x)"
      ],
      "metadata": {
        "id": "gz1caoDAzppq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5286d403-7736-4d65-e35e-8dc33c084d30"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:02<00:00, 238MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[0].keys(), y[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un-boiGn2rvo",
        "outputId": "7f547d1e-6281-4463-b093-7793f56328e6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(odict_keys(['out_conv4_3', 'out_conv7_2', 'out_conv5_3', 'out_conv6_2']),\n",
              " torch.Size([5, 512, 16, 16]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv4_3 = y[0]['out_conv4_3']\n",
        "conv5_3 = y[0]['out_conv5_3'][0]\n",
        "conv6_2 = y[0]['out_conv6_2'][0]\n",
        "conv7_2 = y[0]['out_conv7_2'][0]\n",
        "\n",
        "print(conv4_3.shape, conv5_3.shape, conv6_2.shape, conv7_2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fvp7anur_4Vc",
        "outputId": "7306a21c-c356-414d-fa8e-85105f6ec30d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 512, 64, 64]) torch.Size([5, 512, 32, 32]) torch.Size([5, 512, 32, 32]) torch.Size([5, 512, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ftb(current_layer, former_layer=None):\n",
        "  x = torch.nn.Conv2d(current_layer.shape[1], 256, kernel_size=3, stride=1, padding=1)(current_layer)\n",
        "  x = torch.nn.ReLU(inplace=True)(x)\n",
        "  x = torch.nn.Conv2d(256, 256, kernel_size=3, padding=1)(x)\n",
        "  \n",
        "  if former_layer is None:\n",
        "    return x\n",
        "  elif x.shape == former_layer.shape:\n",
        "    return torch.add(x, former_layer)\n",
        "\n",
        "  else:\n",
        "    d = torch.nn.ConvTranspose2d(former_layer.shape[1], 256, kernel_size=4, stride=2, padding=1)(former_layer)\n",
        "    print(x.shape, d.shape)\n",
        "    return torch.add(x, d)\n",
        "\n",
        "s=ftb(conv4_3, conv5_3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef4PrW4Rh1YO",
        "outputId": "ef1b8013-223c-4380-d59b-9efb87b8999e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 256, 64, 64]) torch.Size([5, 256, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9bI20xu2tznb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ottYC5vczvb1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}