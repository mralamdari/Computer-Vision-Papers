{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1u8VMtqWk82aaJ1x3jn0sECaOnC-Ajo3d",
      "authorship_tag": "ABX9TyMmupcdNF8yhJn0PJwY2WoP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/Computer-Vision-Papers/blob/main/P1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Dxxi3XCEgiGN",
        "outputId": "10821bb8-d264-4c86-b4d6-077c0c0267f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.11.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/'\n",
        "!kaggle datasets download -d nightwitch/railwayrgbd\n",
        "!unzip \\*.zip"
      ],
      "metadata": {
        "id": "kDXGZzAT5BPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7436317c-e193-4dd2-bdc8-24064b579bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading railwayrgbd.zip to /content\n",
            "  3% 153M/5.46G [00:02<00:53, 107MB/s] "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = tf.keras.applications.vgg16.VGG16(weights='imagenet')"
      ],
      "metadata": {
        "id": "BpQ61aN_s7L9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16.summary()"
      ],
      "metadata": {
        "id": "42cX335Os8KP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be9fe1cd-eb46-4784-c6de-0a1d86047868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(vgg16.layers)):\n",
        "  vgg16.layers[i].trainable=False\n",
        "  print(vgg16.layers[i].name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8HFCKQJkigU",
        "outputId": "8c0fdcf4-5250-4b9d-ca9d-bbad94065aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_1\n",
            "block1_conv1\n",
            "block1_conv2\n",
            "block1_pool\n",
            "block2_conv1\n",
            "block2_conv2\n",
            "block2_pool\n",
            "block3_conv1\n",
            "block3_conv2\n",
            "block3_conv3\n",
            "block3_pool\n",
            "block4_conv1\n",
            "block4_conv2\n",
            "block4_conv3\n",
            "block4_pool\n",
            "block5_conv1\n",
            "block5_conv2\n",
            "block5_conv3\n",
            "block5_pool\n",
            "flatten\n",
            "fc1\n",
            "fc2\n",
            "predictions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ftb(current_layer, former_layer=None):\n",
        "  x = tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, activation='relu', padding='same')(current_layer)\n",
        "  x = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same')(x)\n",
        "\n",
        "  if former_layer is None:\n",
        "    return x\n",
        "  \n",
        "  elif x.shape == former_layer.shape:\n",
        "    return tf.keras.layers.Add()([x, former_layer])\n",
        "\n",
        "  else:\n",
        "    d = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=4, strides=2, padding='same')(former_layer)\n",
        "    return tf.keras.layers.Add()([x, d])"
      ],
      "metadata": {
        "id": "FzeSzuayTWLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rfem(x):\n",
        "  channel = x.shape[-1]\n",
        "  #branch1\n",
        "  \n",
        "  x1 = tf.keras.layers.MaxPool2D(pool_size=2, padding='same', strides=1)(x)\n",
        "  x1 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(1, 1), padding='same', activation='relu')(x1)\n",
        "  x1 = tf.keras.layers.BatchNormalization()(x1)\n",
        "\n",
        "  #branch2\n",
        "  x2 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(1, 1), padding='same', activation='relu')(x)\n",
        "  x2 = tf.keras.layers.BatchNormalization()(x2)\n",
        "  x2 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(1, 3), padding='same', activation='relu')(x2)\n",
        "  x2 = tf.keras.layers.BatchNormalization()(x2)\n",
        "\n",
        "  #branch3\n",
        "  x3 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(1, 1), padding='same', activation='relu')(x)\n",
        "  x3 = tf.keras.layers.BatchNormalization()(x3)\n",
        "  x3 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(3, 1), padding='same', activation='relu')(x3)\n",
        "  x3 = tf.keras.layers.BatchNormalization()(x3)\n",
        "\n",
        "  #branch4\n",
        "  x4 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(1, 1), padding='same', activation='relu')(x)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "  x4 = tf.keras.layers.Conv2D(filters=channel//3, kernel_size=(3, 1), padding='same', activation='relu')(x4)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "  x4 = tf.keras.layers.Conv2D(filters=channel//3, kernel_size=(1, 3), padding='same', activation='relu')(x4)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "  x4 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(3, 1), padding='same', activation='relu')(x4)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "  x4 = tf.keras.layers.Conv2D(filters=channel//4, kernel_size=(1, 3), padding='same', activation='relu')(x4)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "\n",
        "  combined_x = tf.keras.layers.Concatenate(axis=-1)([x1, x2, x3, x4])\n",
        "\n",
        "  return tf.keras.layers.Add()([combined_x, x/0.5])"
      ],
      "metadata": {
        "id": "A4KuDR24YwXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_x = tf.keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "x_1  = vgg16.get_layer('input_1')(input_x)\n",
        "\n",
        "x_2  = vgg16.get_layer('block1_conv1')(x_1)\n",
        "x_3  = vgg16.get_layer('block1_conv2')(x_2)\n",
        "x_4  = vgg16.get_layer('block1_pool')(x_3)\n",
        "\n",
        "\n",
        "x_5  = vgg16.get_layer('block2_conv1')(x_4)\n",
        "x_6  = vgg16.get_layer('block2_conv2')(x_5)\n",
        "x_7  = vgg16.get_layer('block2_pool')(x_6)\n",
        "\n",
        "\n",
        "x_8  = vgg16.get_layer('block3_conv1')(x_7)\n",
        "x_9  = vgg16.get_layer('block3_conv2')(x_8)\n",
        "x_10 = vgg16.get_layer('block3_conv3')(x_9)\n",
        "x_11 = vgg16.get_layer('block3_pool')(x_10)\n",
        "\n",
        "\n",
        "x_12 = vgg16.get_layer('block4_conv1')(x_11)\n",
        "x_13 = vgg16.get_layer('block4_conv2')(x_12)\n",
        "x_14 = vgg16.get_layer('block4_conv3')(x_13)\n",
        "x_15 = vgg16.get_layer('block4_pool')(x_14)\n",
        "\n",
        "X1   = vgg16.get_layer('block4_conv3')(rfem(x_13))\n",
        "\n",
        "x_16 = vgg16.get_layer('block5_conv1')(x_15)\n",
        "x_17 = vgg16.get_layer('block5_conv2')(x_16)\n",
        "x_18 = vgg16.get_layer('block5_conv3')(x_17)\n",
        "x_19 = vgg16.get_layer('block5_pool')(x_18)\n",
        "\n",
        "X2   = vgg16.get_layer('block5_conv3')(rfem(X1))\n",
        "\n",
        "x_20 = tf.keras.layers.Conv2D(filters=1024, kernel_size=3, padding='same', activation='relu', name='block6_conv1')(x_19)\n",
        "x_21 = tf.keras.layers.MaxPool2D(pool_size=2, name='block6_pool')(x_20)\n",
        "\n",
        "X3   = tf.keras.layers.Conv2D(filters=1024, kernel_size=3, padding='same', activation='relu', name='block6_conv1')(rfem(X2))\n",
        "\n",
        "\n",
        "x_22 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=2, padding='same', activation='relu', name='block7_conv1')(x_21)\n",
        "x_23 = tf.keras.layers.MaxPool2D(pool_size=2, name='block7_pool')(x_22)\n",
        "\n",
        "X4   = tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=2, padding='same', activation='relu', name='block7_conv1')(rfem(X3))\n",
        "\n",
        "x_24 = tf.keras.layers.Flatten()(x_23)\n",
        "x_25 = tf.keras.layers.Dense(units=4096, activation='relu', name='dense_layer')(x_24)\n",
        "x_26 = tf.keras.layers.Dense(units=7, activation='softmax', name='final_layer')(x_25)\n",
        "\n",
        "\n",
        "X41  = ftb(X4)\n",
        "X42  = rfem(X41)\n",
        "\n",
        "X31  = ftb(X3, X41)\n",
        "X32  = rfem(X31)\n",
        "\n",
        "X21  = ftb(X2, X31)\n",
        "X22  = rfem(X21)\n",
        "\n",
        "X11  = ftb(X1, X21)\n",
        "X12  = rfem(X11)\n",
        "\n",
        "\n",
        "# PDM\n",
        "X4 + X42\n",
        "X3 + X32\n",
        "X2 + X22\n",
        "X1 + X12"
      ],
      "metadata": {
        "id": "o0bQqakqlt_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Model(inputs=input_x, outputs=[X])"
      ],
      "metadata": {
        "id": "6I5wn93QZZmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_short = tf.keras.models.Model(vgg16.input, vgg16.layers[-5].output)\n",
        "\n",
        "model_1 = tf.keras.Sequential([\n",
        "    vgg16_short, \n",
        "    tf.keras.layers.Conv2D(filters=1024, kernel_size=(3, 3), padding='same', activation='relu', name='block6_conv1'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2, name='block6_pool'),\n",
        "    tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), strides=2, padding='same', activation='relu', name='block7_conv1'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2, name='block7_pool'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=4096, activation='relu', name='dense_layer'),\n",
        "    tf.keras.layers.Dense(units=7, activation='softmax', name='final_layer')\n",
        "])\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "U-5Tqc4-W1cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = tf.keras.models.Model(inputs=vgg16.input, outputs=[vgg16_short.get_layer('block4_conv2').output,\n",
        "                                                            vgg16_short.get_layer('block4_conv3').output,\n",
        "                                                            vgg16_short.get_layer('block5_conv3').output,\n",
        "                                                            model_1.get_layer('block6_conv1').output,\n",
        "                                                            model_1.get_layer('block7_conv1').output])"
      ],
      "metadata": {
        "id": "6tc1BmlYWc2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Yolo with Custom Dataset\n",
        "Here you can add your dataset and detect the objects you desire.\n",
        "\n",
        "### There are several ways to gather data for object detection:\n",
        "#### 1. Get Pre-labeled data from Online Resources like [Open Images Dataset](https://storage.googleapis.com/openimages/web/index.html)\n",
        "##### 2. Download Images and Label them yourself \n",
        "(zip the images folder with labels and upload it to your Google Drive)\n",
        "\n",
        "\n",
        "to get Images from [Open Images Dataset](https://storage.googleapis.com/openimages/web/index.html) and convert them to yolo's input types, use [OIDv4 ToolKit](https://github.com/mralamdari/OIDv4_ToolKit.git) that I've adjusted."
      ],
      "metadata": {
        "id": "1qPzTv0b4Zqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#clone OIDv4_ToolKit\n",
        "%cd /content/darknet\n",
        "!git clone https://github.com/mralamdari/OIDv4_ToolKit.git"
      ],
      "metadata": {
        "id": "6Uqo7YZCbL3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "894c3a0f-e6db-4c67-b3f0-40f5bd88eddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/darknet'\n",
            "/content\n",
            "Cloning into 'OIDv4_ToolKit'...\n",
            "remote: Enumerating objects: 499, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 499 (delta 32), reused 52 (delta 31), pack-reused 444\u001b[K\n",
            "Receiving objects: 100% (499/499), 34.11 MiB | 36.27 MiB/s, done.\n",
            "Resolving deltas: 100% (189/189), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install necessary libraries\n",
        "!pip3 install -r requirements.txt\n",
        "!pip install awscli"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSSgHxDk4dt2",
        "outputId": "4e8b16bd-3b66-4220-e30d-f989c2d9163c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: rsa, PyYAML, jmespath, colorama, botocore, s3transfer, awscli\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "Successfully installed PyYAML-5.4.1 awscli-1.27.89 botocore-1.29.89 colorama-0.4.4 jmespath-1.0.1 rsa-4.7.2 s3transfer-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Move to OIDv4_ToolKit folder\n",
        "%cd OIDv4_ToolKit\n",
        "\n",
        "NUM_CLASSES=1\n",
        "#Mention the number of objects you want to train\n",
        "\n",
        "#Write your desired objects (--classes) and data type (--type_csv)  and the number of images you want (--limit)\n",
        "!python3 main.py downloader --classes Train --type_csv train --limit 50000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyC7L5E74epQ",
        "outputId": "94626c33-a37a-4d6a-b4f5-4b0eae526fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/OIDv4_ToolKit\n",
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Train.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the class-descriptions-boxable.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...145%, 0 MB, 57850 KB/s, 0 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File class-descriptions-boxable.csv downloaded into OID/csv_folder/class-descriptions-boxable.csv.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the train-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...100%, 1138 MB, 35995 KB/s, 32 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File train-annotations-bbox.csv downloaded into OID/csv_folder/train-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mTrain\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 10081 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 50000 images.\u001b[0m\n",
            "    [INFO] | Download of 10081 images in train.\u001b[0m\n",
            "100% 10081/10081 [1:56:58<00:00,  1.44it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Train of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python mralamdari_annotations_converter.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4df2qgi4wyz",
        "outputId": "5b841b15-8c48-4898-a172-7ec1a81c4daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently in subdirectory: train\n",
            "Converting annotations for class: Train\n",
            "100% 10081/10081 [04:20<00:00, 38.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0JC6ZiyAZcds"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}