{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UZsOLhqj_A9C",
        "pmWa8_62qsC1",
        "ymuYPCXF7jYl"
      ],
      "mount_file_id": "1cPJphDL6x1dCVFW5-TWFfuuYz5w5O1PP",
      "authorship_tag": "ABX9TyPQeQhqxeLpmFRj6687Gkjg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/Computer-Vision-Papers/blob/main/Violence_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from IPython.display import clear_output "
      ],
      "metadata": {
        "id": "zXD6MSIS8rkE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Datasets"
      ],
      "metadata": {
        "id": "UZsOLhqj_A9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/airtlab/A-Dataset-for-Automatic-Violence-Detection-in-Videos.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qpL9sGF---i",
        "outputId": "dc756854-1e85-4710-e6a0-196bce095fa6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'A-Dataset-for-Automatic-Violence-Detection-in-Videos'...\n",
            "remote: Enumerating objects: 376, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 376 (delta 3), reused 11 (delta 3), pack-reused 364\u001b[K\n",
            "Receiving objects: 100% (376/376), 1.02 GiB | 40.17 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "Updating files: 100% (355/355), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgsh4hWTkxg-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f786d8-4baa-4adb-928e-40a47319f000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading real-life-violence-situations-dataset.zip to /content\n",
            "  4% 161M/3.58G [00:03<00:37, 98.8MB/s]"
          ]
        }
      ],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive'\n",
        "!kaggle datasets download -d mohamedmustafa/real-life-violence-situations-dataset\n",
        "!kaggle datasets download -d adiamaan/movie-subtitle-dataset\n",
        "!unzip \\*.zip && rm *.zip\n",
        "!git clone https://github.com/airtlab/A-Dataset-for-Automatic-Violence-Detection-in-Videos.git\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/NonViolence/', exist_ok=True)\n",
        "os.makedirs('/content/Violence/', exist_ok=True)\n",
        "\n",
        "nv = '/content/Real Life Violence Dataset/NonViolence/'\n",
        "v = '/content/Real Life Violence Dataset/Violence/'\n",
        "\n",
        "for V in [v, nv]:\n",
        "  for i in os.listdir(V):\n",
        "    R = V+i\n",
        "    os.replace(R, R.replace('Real Life Violence Dataset/', ''))"
      ],
      "metadata": {
        "id": "7tSaSxl9_AcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/A-Dataset-for-Automatic-Violence-Detection-in-Videos/violence-detection-dataset/'\n",
        "choices = ['/content/NonViolence/', '/content/NonViolence/', '/content/Violence/', '/content/Violence/']\n",
        "\n",
        "for id, V in enumerate(['non-violent/cam1/', 'non-violent/cam2/', 'violent/cam1/', 'violent/cam2/']):\n",
        "  for i in os.listdir(path+V):\n",
        "    os.replace(path+V+i, choices[id]+i)"
      ],
      "metadata": {
        "id": "jOts7tMI_sl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/data/', exist_ok=True)\n",
        "os.replace('/content/NonViolence/', '/content/data/NonViolence/')\n",
        "os.replace('/content/Violence/', '/content/data/Violence/')"
      ],
      "metadata": {
        "id": "1NDZZ8C-f59J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2"
      ],
      "metadata": {
        "id": "pmWa8_62qsC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall emoji\n",
        "!pip install emoji==1.7.0\n",
        "!pip install text2emotion\n",
        "\n",
        "import text2emotion as te\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "jYQ6s3di109g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = \"I was asked to sign a third party contract a week out from stay\"\n",
        "te.get_emotion(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMnVFyWGqwQ3",
        "outputId": "a9c83c15-f70e-4e41-938e-79180b556f2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Happy': 0.0, 'Angry': 0.25, 'Surprise': 0.0, 'Sad': 0.0, 'Fear': 0.75}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/datasets/adiamaan/movie-subtitle-dataset/code"
      ],
      "metadata": {
        "id": "-nQNOLmh9iI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive'\n",
        "!kaggle datasets download -d adiamaan/movie-subtitle-dataset\n",
        "!unzip \\*.zip && rm *.zip\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "rJF_bZxbrO7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "sub = pd.read_csv('/content/movies_subtitles.csv')\n",
        "meta = pd.read_csv('/content/movies_meta.csv')"
      ],
      "metadata": {
        "id": "IY6sX6EC9RzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "abbreviations = {\n",
        "    \"$\" : \" dollar \",\n",
        "    \"â‚¬\" : \" euro \",\n",
        "    \"4ao\" : \"for adults only\",\n",
        "    \"a.m\" : \"before midday\",\n",
        "    \"a3\" : \"anytime anywhere anyplace\",\n",
        "    \"aamof\" : \"as a matter of fact\",\n",
        "    \"acct\" : \"account\",\n",
        "    \"adih\" : \"another day in hell\",\n",
        "    \"afaic\" : \"as far as i am concerned\",\n",
        "    \"afaict\" : \"as far as i can tell\",\n",
        "    \"afaik\" : \"as far as i know\",\n",
        "    \"afair\" : \"as far as i remember\",\n",
        "    \"afk\" : \"away from keyboard\",\n",
        "    \"app\" : \"application\",\n",
        "    \"approx\" : \"approximately\",\n",
        "    \"apps\" : \"applications\",\n",
        "    \"asap\" : \"as soon as possible\",\n",
        "    \"asl\" : \"age, sex, location\",\n",
        "    \"atk\" : \"at the keyboard\",\n",
        "    \"ave.\" : \"avenue\",\n",
        "    \"aymm\" : \"are you my mother\",\n",
        "    \"ayor\" : \"at your own risk\", \n",
        "    \"b&b\" : \"bed and breakfast\",\n",
        "    \"b+b\" : \"bed and breakfast\",\n",
        "    \"b.c\" : \"before christ\",\n",
        "    \"b2b\" : \"business to business\",\n",
        "    \"b2c\" : \"business to customer\",\n",
        "    \"b4\" : \"before\",\n",
        "    \"b4n\" : \"bye for now\",\n",
        "    \"b@u\" : \"back at you\",\n",
        "    \"bae\" : \"before anyone else\",\n",
        "    \"bak\" : \"back at keyboard\",\n",
        "    \"bbbg\" : \"bye bye be good\",\n",
        "    \"bbc\" : \"british broadcasting corporation\",\n",
        "    \"bbias\" : \"be back in a second\",\n",
        "    \"bbl\" : \"be back later\",\n",
        "    \"bbs\" : \"be back soon\",\n",
        "    \"be4\" : \"before\",\n",
        "    \"bfn\" : \"bye for now\",\n",
        "    \"blvd\" : \"boulevard\",\n",
        "    \"bout\" : \"about\",\n",
        "    \"brb\" : \"be right back\",\n",
        "    \"bros\" : \"brothers\",\n",
        "    \"brt\" : \"be right there\",\n",
        "    \"bsaaw\" : \"big smile and a wink\",\n",
        "    \"btw\" : \"by the way\",\n",
        "    \"bwl\" : \"bursting with laughter\",\n",
        "    \"c/o\" : \"care of\",\n",
        "    \"cet\" : \"central european time\",\n",
        "    \"cf\" : \"compare\",\n",
        "    \"cia\" : \"central intelligence agency\",\n",
        "    \"csl\" : \"can not stop laughing\",\n",
        "    \"cu\" : \"see you\",\n",
        "    \"cul8r\" : \"see you later\",\n",
        "    \"cv\" : \"curriculum vitae\",\n",
        "    \"cwot\" : \"complete waste of time\",\n",
        "    \"cya\" : \"see you\",\n",
        "    \"cyt\" : \"see you tomorrow\",\n",
        "    \"dae\" : \"does anyone else\",\n",
        "    \"dbmib\" : \"do not bother me i am busy\",\n",
        "    \"diy\" : \"do it yourself\",\n",
        "    \"dm\" : \"direct message\",\n",
        "    \"dwh\" : \"during work hours\",\n",
        "    \"e123\" : \"easy as one two three\",\n",
        "    \"eet\" : \"eastern european time\",\n",
        "    \"eg\" : \"example\",\n",
        "    \"embm\" : \"early morning business meeting\",\n",
        "    \"encl\" : \"enclosed\",\n",
        "    \"encl.\" : \"enclosed\",\n",
        "    \"etc\" : \"and so on\",\n",
        "    \"faq\" : \"frequently asked questions\",\n",
        "    \"fawc\" : \"for anyone who cares\",\n",
        "    \"fb\" : \"facebook\",\n",
        "    \"fc\" : \"fingers crossed\",\n",
        "    \"fig\" : \"figure\",\n",
        "    \"fimh\" : \"forever in my heart\", \n",
        "    \"ft.\" : \"feet\",\n",
        "    \"ft\" : \"featuring\",\n",
        "    \"ftl\" : \"for the loss\",\n",
        "    \"ftw\" : \"for the win\",\n",
        "    \"fwiw\" : \"for what it is worth\",\n",
        "    \"fyi\" : \"for your information\",\n",
        "    \"g9\" : \"genius\",\n",
        "    \"gahoy\" : \"get a hold of yourself\",\n",
        "    \"gal\" : \"get a life\",\n",
        "    \"gcse\" : \"general certificate of secondary education\",\n",
        "    \"gfn\" : \"gone for now\",\n",
        "    \"gg\" : \"good game\",\n",
        "    \"gl\" : \"good luck\",\n",
        "    \"glhf\" : \"good luck have fun\",\n",
        "    \"gmt\" : \"greenwich mean time\",\n",
        "    \"gmta\" : \"great minds think alike\",\n",
        "    \"gn\" : \"good night\",\n",
        "    \"g.o.a.t\" : \"greatest of all time\",\n",
        "    \"goat\" : \"greatest of all time\",\n",
        "    \"goi\" : \"get over it\",\n",
        "    \"gps\" : \"global positioning system\",\n",
        "    \"gr8\" : \"great\",\n",
        "    \"gratz\" : \"congratulations\",\n",
        "    \"gyal\" : \"girl\",\n",
        "    \"h&c\" : \"hot and cold\",\n",
        "    \"hp\" : \"horsepower\",\n",
        "    \"hr\" : \"hour\",\n",
        "    \"hrh\" : \"his royal highness\",\n",
        "    \"ht\" : \"height\",\n",
        "    \"ibrb\" : \"i will be right back\",\n",
        "    \"ic\" : \"i see\",\n",
        "    \"icq\" : \"i seek you\",\n",
        "    \"icymi\" : \"in case you missed it\",\n",
        "    \"idc\" : \"i do not care\",\n",
        "    \"idgadf\" : \"i do not give a damn fuck\",\n",
        "    \"idgaf\" : \"i do not give a fuck\",\n",
        "    \"idk\" : \"i do not know\",\n",
        "    \"ie\" : \"that is\",\n",
        "    \"i.e\" : \"that is\",\n",
        "    \"ifyp\" : \"i feel your pain\",\n",
        "    \"IG\" : \"instagram\",\n",
        "    \"iirc\" : \"if i remember correctly\",\n",
        "    \"ilu\" : \"i love you\",\n",
        "    \"ily\" : \"i love you\",\n",
        "    \"imho\" : \"in my humble opinion\",\n",
        "    \"imo\" : \"in my opinion\",\n",
        "    \"imu\" : \"i miss you\",\n",
        "    \"iow\" : \"in other words\",\n",
        "    \"irl\" : \"in real life\",\n",
        "    \"j4f\" : \"just for fun\",\n",
        "    \"jic\" : \"just in case\",\n",
        "    \"jk\" : \"just kidding\",\n",
        "    \"jsyk\" : \"just so you know\",\n",
        "    \"l8r\" : \"later\",\n",
        "    \"lb\" : \"pound\",\n",
        "    \"lbs\" : \"pounds\",\n",
        "    \"ldr\" : \"long distance relationship\",\n",
        "    \"lmao\" : \"laugh my ass off\",\n",
        "    \"lmfao\" : \"laugh my fucking ass off\",\n",
        "    \"lol\" : \"laughing out loud\",\n",
        "    \"ltd\" : \"limited\",\n",
        "    \"ltns\" : \"long time no see\",\n",
        "    \"m8\" : \"mate\",\n",
        "    \"mf\" : \"motherfucker\",\n",
        "    \"mfs\" : \"motherfuckers\",\n",
        "    \"mfw\" : \"my face when\",\n",
        "    \"mofo\" : \"motherfucker\",\n",
        "    \"mph\" : \"miles per hour\",\n",
        "    \"mr\" : \"mister\",\n",
        "    \"mrw\" : \"my reaction when\",\n",
        "    \"ms\" : \"miss\",\n",
        "    \"mte\" : \"my thoughts exactly\",\n",
        "    \"nagi\" : \"not a good idea\",\n",
        "    \"nbc\" : \"national broadcasting company\",\n",
        "    \"nbd\" : \"not big deal\",\n",
        "    \"nfs\" : \"not for sale\",\n",
        "    \"ngl\" : \"not going to lie\",\n",
        "    \"nhs\" : \"national health service\",\n",
        "    \"nrn\" : \"no reply necessary\",\n",
        "    \"nsfl\" : \"not safe for life\",\n",
        "    \"nsfw\" : \"not safe for work\",\n",
        "    \"nth\" : \"nice to have\",\n",
        "    \"nvr\" : \"never\",\n",
        "    \"nyc\" : \"new york city\",\n",
        "    \"oc\" : \"original content\",\n",
        "    \"og\" : \"original\",\n",
        "    \"ohp\" : \"overhead projector\",\n",
        "    \"oic\" : \"oh i see\",\n",
        "    \"omdb\" : \"over my dead body\",\n",
        "    \"omg\" : \"oh my god\",\n",
        "    \"omw\" : \"on my way\",\n",
        "    \"p.a\" : \"per annum\",\n",
        "    \"p.m\" : \"after midday\",\n",
        "    \"pm\" : \"prime minister\",\n",
        "    \"poc\" : \"people of color\",\n",
        "    \"pov\" : \"point of view\",\n",
        "    \"pp\" : \"pages\",\n",
        "    \"ppl\" : \"people\",\n",
        "    \"prw\" : \"parents are watching\",\n",
        "    \"ps\" : \"postscript\",\n",
        "    \"pt\" : \"point\",\n",
        "    \"ptb\" : \"please text back\",\n",
        "    \"pto\" : \"please turn over\",\n",
        "    \"qpsa\" : \"what happens\", #\"que pasa\",\n",
        "    \"ratchet\" : \"rude\",\n",
        "    \"rbtl\" : \"read between the lines\",\n",
        "    \"rlrt\" : \"real life retweet\", \n",
        "    \"rofl\" : \"rolling on the floor laughing\",\n",
        "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
        "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
        "    \"rt\" : \"retweet\",\n",
        "    \"ruok\" : \"are you ok\",\n",
        "    \"sfw\" : \"safe for work\",\n",
        "    \"sk8\" : \"skate\",\n",
        "    \"smh\" : \"shake my head\",\n",
        "    \"sq\" : \"square\",\n",
        "    \"srsly\" : \"seriously\", \n",
        "    \"ssdd\" : \"same stuff different day\",\n",
        "    \"tbh\" : \"to be honest\",\n",
        "    \"tbs\" : \"tablespooful\",\n",
        "    \"tbsp\" : \"tablespooful\",\n",
        "    \"tfw\" : \"that feeling when\",\n",
        "    \"thks\" : \"thank you\",\n",
        "    \"tho\" : \"though\",\n",
        "    \"thx\" : \"thank you\",\n",
        "    \"tia\" : \"thanks in advance\",\n",
        "    \"til\" : \"today i learned\",\n",
        "    \"tl;dr\" : \"too long i did not read\",\n",
        "    \"tldr\" : \"too long i did not read\",\n",
        "    \"tmb\" : \"tweet me back\",\n",
        "    \"tntl\" : \"trying not to laugh\",\n",
        "    \"ttyl\" : \"talk to you later\",\n",
        "    \"u\" : \"you\",\n",
        "    \"u2\" : \"you too\",\n",
        "    \"u4e\" : \"yours for ever\",\n",
        "    \"utc\" : \"coordinated universal time\",\n",
        "    \"w/\" : \"with\",\n",
        "    \"w/o\" : \"without\",\n",
        "    \"w8\" : \"wait\",\n",
        "    \"wassup\" : \"what is up\",\n",
        "    \"wb\" : \"welcome back\",\n",
        "    \"wtf\" : \"what the fuck\",\n",
        "    \"wtg\" : \"way to go\",\n",
        "    \"wtpa\" : \"where the party at\",\n",
        "    \"wuf\" : \"where are you from\",\n",
        "    \"wuzup\" : \"what is up\",\n",
        "    \"wywh\" : \"wish you were here\",\n",
        "    \"yd\" : \"yard\",\n",
        "    \"ygtr\" : \"you got that right\",\n",
        "    \"ynk\" : \"you never know\",\n",
        "    \"zzz\" : \"sleeping bored and tired\"\n",
        "}\n",
        "\n",
        "def convert_abb(x):\n",
        "    if type(x) != str:\n",
        "      return str(x)\n",
        "    word_list = x.split()\n",
        "    r_string = []\n",
        "    for word in word_list:\n",
        "        r_string.append(abbreviations[word.lower()] if word.lower() in abbreviations.keys() else word)\n",
        "    return ' '.join(r_string)\n"
      ],
      "metadata": {
        "id": "Df0N9bSvvk2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub['text'] = sub.text.apply(convert_abb)\n",
        "\n",
        "# # Remove emojis\n",
        "# train_df['clean_text'] = train_df.clean_text.apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))\n",
        "# test_df['clean_text'] = test_df.clean_text.apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))"
      ],
      "metadata": {
        "id": "mkbQAmvivu3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sub['text'] = sub.text.apply(convert_abb)\n",
        "\n",
        "ss = sub.text.apply(lambda x: te.get_emotion(x))"
      ],
      "metadata": {
        "id": "NEXAzUOW932Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('/content/drive/MyDrive/forage/data.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(ss, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "BvS3qFy2ykQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ll"
      ],
      "metadata": {
        "id": "_vadsak94juF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('/content/drive/MyDrive/forage/data.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(ss, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "lGgfTtEh63Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Faces Extract"
      ],
      "metadata": {
        "id": "ymuYPCXF7jYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import shutil\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!mkdir frame\n",
        "!mkdir faces\n",
        "\n",
        "\n",
        "d_frame='/content/frame/'\n",
        "d_faces='/content/faces/'\n",
        "\n",
        "def video_2_frames(video_file, image_dir=d_frame, image_file='img_%s.png'):\n",
        "    i = 0\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    while(cap.isOpened()):\n",
        "        flag, frame = cap.read()\n",
        "        if flag == False:\n",
        "            break\n",
        "        cv2.imwrite(image_dir+image_file % str(i).zfill(6), frame) \n",
        "        i += 1\n",
        "    cap.release()"
      ],
      "metadata": {
        "id": "h4HO7-H57LyG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe6e0ad0-a75e-4b01-d328-8f24f7f15a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory â€˜facesâ€™: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_2_frames('/content/real life violence situations/Real Life Violence Dataset/NonViolence/NV_100.mp4')\n",
        "\n",
        "frame_paths=[]\n",
        "for file in os.listdir(d_frame):\n",
        "    frame_paths+=[os.path.join(d_frame,file)]\n",
        "frame_paths=sorted(frame_paths)\n",
        "print(frame_paths[0:5])"
      ],
      "metadata": {
        "id": "mk7MNwkB78Ia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd80658b-681c-4665-c75c-31a291b2469e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/frame/img_000000.png', '/content/frame/img_000001.png', '/content/frame/img_000002.png', '/content/frame/img_000003.png', '/content/frame/img_000004.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget --no-check-certificate \\\n",
        "#     https://raw.githubusercontent.com/computationalcore/introduction-to-opencv/master/assets/haarcascade_frontalface_default.xml \\\n",
        "#     -O haarcascade_frontalface_default.xml\n",
        "# !wget --no-check-certificate \\\n",
        "#     https://raw.githubusercontent.com/computationalcore/introduction-to-opencv/master/utils/common.py \\\n",
        "#     -O common.py\n",
        "\n",
        "import cv2 \n",
        "# import common #some useful opencv functions\n",
        "import numpy as np\n",
        "\n",
        "counter = 0\n",
        "for img_path in frame_paths:\n",
        "  image = cv2.imread(img_path)\n",
        "  image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  face_cascade = cv2.CascadeClassifier('/content/haarcascade_frontalface_default.xml')\n",
        "  faces = face_cascade.detectMultiScale(image, 1.3, 5)\n",
        "  print(faces)\n",
        "  for (x, y, w, h) in faces:\n",
        "      counter += 1\n",
        "      cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "      # face = image[y:y + h, x:x + w]\n",
        "      offset = 10\n",
        "      face_section = image[y-offset:y+h+offset,x-offset:x+w+offset]\n",
        "      face_section = cv2.resize(face_section,(100,100))\n",
        "\n",
        "      # print(face_section)\n",
        "      cv2.imwrite(f'/content/face{counter}.jpg', face_section)\n",
        "  # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv21lIZNl7TZ",
        "outputId": "20dc0570-2edb-4037-9f17-a659e094bd1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n",
            "()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frame_paths=[]\n",
        "for file in os.listdir(d_frame):\n",
        "    frame_paths+=[os.path.join(d_frame,file)]\n",
        "frame_paths=sorted(frame_paths)\n",
        "print(frame_paths[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERZPuOXNoUK7",
        "outputId": "184a2e98-3dea-4756-c2cc-8e4ca0e320a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/frame/img_000000.png', '/content/frame/img_000001.png', '/content/frame/img_000002.png', '/content/frame/img_000003.png', '/content/frame/img_000004.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "#Init Camera\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Face Detection\n",
        "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
        "\n",
        "while True:\n",
        "    ret,frame = cap.read()\n",
        "    gray_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
        "    if ret==False:\n",
        "        continue\n",
        "    faces = face_cascade.detectMultiScale(frame,1.3,5)\n",
        "    print(faces)\n",
        "    for (x,y,w,h) in faces:\n",
        "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
        "        cv2.rectangle(gray_frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
        "\n",
        "    cv2.imshow(\"Video Frame\",frame)\n",
        "    cv2.imshow(\"Gray Frame\" ,gray_frame)\n",
        "\n",
        "    key_pressed = cv2.waitKey(1) & 0xFF\n",
        "    if key_pressed == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "67E-fV0A8Itn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#Init Camera\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Face Detection\n",
        "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
        "\n",
        "skip = 0\n",
        "face_data = []\n",
        "dataset_path = './image_data/'\n",
        "file_name = input(\"Enter the name of the person : \")\n",
        "while True:\n",
        "    ret,frame = cap.read()\n",
        "\n",
        "    if ret==False:\n",
        "        continue\n",
        "\n",
        "\n",
        "    gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(frame,1.3,5)\n",
        "    if len(faces)==0:\n",
        "        continue\n",
        "\n",
        "    faces = sorted(faces,key=lambda f:f[2]*f[3])\n",
        "\n",
        "    # Pick the last face (because it is the largest face acc to area(f[2]*f[3]))\n",
        "    for face in faces[-1:]:\n",
        "        x,y,w,h = face\n",
        "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
        "\n",
        "\n",
        "\n",
        "    #Extract (Crop out the required face) : Region of Interest\n",
        "    offset = 10\n",
        "    face_section = frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
        "    face_section = cv2.resize(face_section,(100,100))\n",
        "\n",
        "    skip += 1\n",
        "    if skip%10==0:\n",
        "        face_data.append(face_section)\n",
        "        print(len(face_data))\n",
        "\n",
        "\n",
        "    cv2.imshow(\"Frame\",frame)\n",
        "    cv2.imshow(\"Face Section\",face_section)\n",
        "\n",
        "    key_pressed = cv2.waitKey(1) & 0xFF\n",
        "    if key_pressed == ord('q'):\n",
        "        break\n",
        "\n",
        "# Convert our face list array into a numpy array\n",
        "face_data = np.asarray(face_data)\n",
        "face_data = face_data.reshape((face_data.shape[0],-1))\n",
        "print(face_data.shape)\n",
        "\n",
        "# Save this data into file system\n",
        "np.save(dataset_path+file_name+'.npy',face_data)\n",
        "print(\"Data Successfully save at \"+dataset_path+file_name+'.npy')\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "PgHpeTWgnWBS",
        "outputId": "e826109d-d210-4e17-dd10-088a3854acff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-8d5b34000487>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mface_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./image_data/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the name of the person : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np \n",
        "import os \n",
        "\n",
        "def distance(v1, v2):\n",
        "    # Eucledian \n",
        "    return np.sqrt(((v1-v2)**2).sum())\n",
        "\n",
        "def knn(train, test, k=5):\n",
        "    dist = []\n",
        "\n",
        "    for i in range(train.shape[0]):\n",
        "        # Get the vector and label\n",
        "        ix = train[i, :-1]\n",
        "        iy = train[i, -1]\n",
        "        # Compute the distance from test point\n",
        "        d = distance(test, ix)\n",
        "        dist.append([d, iy])\n",
        "    # Sort based on distance and get top k\n",
        "    dk = sorted(dist, key=lambda x: x[0])[:k]\n",
        "    # Retrieve only the labels\n",
        "    labels = np.array(dk)[:, -1]\n",
        "\n",
        "    # Get frequencies of each label\n",
        "    output = np.unique(labels, return_counts=True)\n",
        "    # Find max frequency and corresponding label\n",
        "    index = np.argmax(output[1])\n",
        "    return output[0][index]\n",
        "\n",
        "\n",
        "#Init Camera\n",
        "# cap = cv2.VideoCapture(0)\n",
        "\n",
        "# # Face Detection\n",
        "# face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
        "\n",
        "# skip = 0\n",
        "# dataset_path = './image_data/'\n",
        "\n",
        "# face_data = [] \n",
        "# labels = []\n",
        "\n",
        "# class_id = 0 # Labels for the given file\n",
        "# names = {} #Mapping btw id - name\n",
        "\n",
        "\n",
        "# # Data Preparation\n",
        "# for fx in os.listdir(dataset_path):\n",
        "#     if fx.endswith('.npy'):\n",
        "#        #Create a mapping btw class_id and name\n",
        "#         names[class_id] = fx[:-4]\n",
        "#         print(\"Loaded \"+fx)\n",
        "#         data_item = np.load(dataset_path+fx)\n",
        "#         face_data.append(data_item)\n",
        "\n",
        "#         #Create Labels for the class\n",
        "#         target = class_id*np.ones((data_item.shape[0],))\n",
        "#         class_id += 1\n",
        "#         labels.append(target)\n",
        "\n",
        "# face_dataset = np.concatenate(face_data,axis=0)\n",
        "# face_labels = np.concatenate(labels,axis=0).reshape((-1,1))\n",
        "\n",
        "# print(face_dataset.shape)\n",
        "# print(face_labels.shape)\n",
        "\n",
        "# trainset = np.concatenate((face_dataset,face_labels),axis=1)\n",
        "# print(trainset.shape)\n",
        "\n",
        "# Testing \n",
        "\n",
        "while True:\n",
        "    ret,frame = cap.read()\n",
        "    if ret == False:\n",
        "        continue\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(frame,1.3,5)\n",
        "    if(len(faces)==0):\n",
        "        continue\n",
        "\n",
        "    for face in faces:\n",
        "        x,y,w,h = face\n",
        "\n",
        "        #Get the face ROI\n",
        "        offset = 10\n",
        "        face_section = frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
        "        face_section = cv2.resize(face_section,(100,100))\n",
        "\n",
        "        #Predicted Label (out)\n",
        "        out = knn(trainset,face_section.flatten())\n",
        "\n",
        "        #Display on the screen the name and rectangle around it\n",
        "        pred_name = names[int(out)]\n",
        "        cv2.putText(frame,pred_name,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2,cv2.LINE_AA)\n",
        "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
        "\n",
        "    cv2.imshow(\"Faces\",frame)\n",
        "\n",
        "    key = cv2.waitKey(1) & 0xFF\n",
        "    if key==ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "c9Q-QLO_nEIe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}